{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9effa9-4069-4e71-94dc-b054731badc9",
   "metadata": {},
   "source": [
    "# Problem Set-up:\n",
    "\n",
    "The monitoring network optimization problem has the follwing main components: \n",
    "\n",
    "1. Compare streamflow probability distributions (compute pairwise KL divergence), \n",
    "2. Develop a model to predict divergence of distributions from basin attributes, and \n",
    "3. Apply the model to the ungauged basin (decision) space.\n",
    "4. Express the uncertainty in the expected information gain from (greedy) network expansion\n",
    "5. Rank the existing network for expected total information loss from network contraction\n",
    "\n",
    "## Make a large number of probability distribution comparisons \n",
    "\n",
    "* the observed data $X = \\{(R_1, B_1), (R_2, B_2), \\dots, (R_N, B_N)\\}$ represents a network of $\\text{M}$ streamflow monitoring locations, where:  \n",
    "  * $R$ is a vector of **mean daily unit area runoff (UAR)** over a period of observation, and \n",
    "  * $B$ is a vector of **basin attributes** (assumed to be static in time)\n",
    "* given $R$, let $Z = C(R)$, where $C \\in \\mathcal{C}$ is a quantization (encoding) scheme among many possible.  \n",
    "    * **Problem 1**: How can $C$ be chosen to minimize quantization noise and maximize the mutual information between R and Z?\n",
    "* let $\\mathcal{R} = R\\times R$ represent the set of all **pairs** of $R$ (the Cartesian product), denoted as $\\{ (R_i, R_j) | R_i, R_j \\in R  \\text{ and } i \\neq j \\}$ \n",
    "    * $(R_i, R_j) \\in \\mathcal{R}$ is subject to a minimum overlapping interval ($t_{min}$) between $R_i$ and $R_j$.\n",
    "* let $Y$ denote the input variable (the covariate vector) representing a measure of divergence between each $(R_i, R_j) \\in \\mathcal{R} \\text{ where } i \\neq j$ and the concurrent record criterion $t_{min}$ is met.\n",
    "* $Y$ is then defined by the Kullback-Leibler (KL) divergence of an observed distribution $P$ and an approximate model of the observed data $Q$:  $$D_{KL}(P_i || Q_j) = \\sum_{\\omega \\in \\mathcal{\\Omega}} p_i(\\omega) \\log \\left( \\frac{p_i(\\omega)}{q_j(\\omega)} \\right) $$\n",
    "    * $P$ is the probability mass function (PMF) describing the observed distribution of UAR ($R_i$), \n",
    "    * $Q$ is the PMF of \"simulated\" UAR obtained by assuming UAR is equal to $R$ at location $j$.  This is simply an equal unit area runoff model. \n",
    "    * $P$ and $Q$ are defined for all states $\\omega \\in \\Omega$, and $\\Omega$ is defined by the quantization scheme $C$.\n",
    "* **Problem 2**: $q(\\omega_i) = 0$ is inadmissible, how can a prior distribution be set to have minimal influence?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f80e7-1189-489e-b52d-46b0c169cdb6",
   "metadata": {},
   "source": [
    "## Predict divergence of distributions from basin attributes\n",
    "\n",
    "* let $\\delta (\\theta)$ represent a gradient-boosted regression model (XGBoost) for predicting KL divergence $(Y)$ from basin attributes $(B)$, \n",
    "* let $\\theta \\in \\Theta$ represent a model parameterization in the space of hyperparameters for $\\delta$.\n",
    "\n",
    "### Loss Function $\\mathcal{L}(Y, \\delta(\\theta))$\n",
    "\n",
    "* absolute error is used as the objective function in XGBoost because the residuals are not normally distributed and $\\theta$ is sensitive to outliers.\n",
    "* since $Y$ is generated from all **pairs** of $R$, leaving out $(R_i, R_j)$ pairs for validation is not enough since $R_i$ can occur in up to $M-1$ pairings (though in practice much smaller). \n",
    "* use Monte Carlo (MC) simulation to mitigate selection bias. \n",
    "    * $\\theta$ is held constant across $n_{trials}$ **trials** in a given simulation.\n",
    "    * let $S$ be a subset of $\\mathcal{R}$ obtained by excluding $n_{exclude}$ elements from $R$.  Elements are excluded by:\n",
    "        * random selection to test selection bias, and \n",
    "        * geographic location to test spatial bias,\n",
    "    * the **mean loss** of one simulation (ensemble) is computed from the complement of $S$, $S^c = \\{ (R_i, R_j) | (R_i, R_j) \\notin S \\}$ such that the model is tested out of sample $n_{trials}$ times.\n",
    "* the parameter space $\\Theta$ is searched repeatedly to find an approximately optimal parameterization $\\theta^*$ that yields the lowest mean MC simulation loss from $\\mathcal{L}(Y, \\delta(\\theta^*))$.\n",
    "* **Problem 3**: how can model uncertainty be expressed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b4aba-4cbc-4d5e-b584-83a001fbb194",
   "metadata": {},
   "source": [
    "## Apply the Model to the Decision Space\n",
    "\n",
    "* let $A$ represent the space of ($k$) unmonitored basins. \n",
    "* given $\\delta(\\theta^*)$, let $\\hat Y_{bk}$ represent the **baseline** information about $A_k$, defined as: \n",
    "    * the expected additional bits of information (per observation) needed to fully describe the unit area runoff at an unmonitored location $A_k$.\n",
    "    * the baseline can also be thought of as the compression provided by the current network about the unmonitored basin $A_k$\n",
    "* for each unmonitored basin $A_k \\in A$, compute the baseline information: \n",
    "    * let $\\hat Y_{bk}$ represent the minimum expected divergence among **monitored** basins $\\{ (A_k, R_j) | R_i \\in R \\}$, given by:  \n",
    "  $$\\hat Y_{bk} = \\min_{i : (A_k, R_i) \\in A \\times R} \\delta(\\theta^*)$$  \n",
    "    * let $\\hat Y_{kl}$ represent the minimum expected divergence among **unmonitored** basins $A_l \\in A, k \\neq l$. \n",
    "        * for each $A_k$, find the set of locations $A_l$ where the expected divergence is less than the baseline value for that location $\\hat Y_{kl} < \\hat Y_{kb}$. \n",
    "        * Where $\\hat Y_{kl} < \\hat Y_{kb}$ is satisfied, monitoring location $l$ is expected to provide more information about location $k$ than the current monitoring network provides.  \n",
    "        * Monitoring at location $l$ is expected to reduce the surprise about $k$ by $\\hat Y_{kb} - \\hat Y_{kl}$ bits per sample, \n",
    "        * In other words reduce the number of yes/no questions needed to fully describe $R_k$\n",
    "* let $G_k$ denote the total \"surprise reduction\" of $A_k$, defined as the expected information about the unmonitored space $A$ gained from monitoring element $A_k$.\n",
    "* important to express uncertainty in $G_k$ as stated above re: **Problem 3**\n",
    "* $G_k$ can be used to decide the next monitoring location (greedy selection), where greater values represent a greater expected amount of information about $A$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30117ebc-9a0e-40a2-bead-5aabd18f78f3",
   "metadata": {},
   "source": [
    "## Problems\n",
    "\n",
    "### **Problem 1**: Quantization $(C)$\n",
    "\n",
    "* $C$ is defined by the set of equal intervals $I$ that span from $R_{ij}^a = min\\left(min(R_i), min(R_j) \\right)$ to $R_{ij}^b = max\\left(max(R_i), max(R_j)\\right)$.\n",
    "    * interval $I_k = \\left[ R_{ij}^a + \\frac{k(r_{ij}^b)}{n}, R_{ij}^a +  \\frac{k+1(r_{ij}^b)}{n} \\right]$ where $n = 2^b$ is the dictionary size\n",
    "* it is advantageous to quantize runoff to address (some part of) heteroscedastic measurement error:  \n",
    "    * log-transform runoff   \n",
    "    * equal width binning (in log space) to reflect measurement error\n",
    "* parametric vs. nonparametric distributions\n",
    "    * parametric:\n",
    "        * avoids $q(\\omega) = 0$\n",
    "        * information is lost in parametric fit\n",
    "        * i.e. gamma works often, but what about bimodal distributions or ephemeral streams?\n",
    "    * nonparametric:\n",
    "        * must set prior to address $q(\\omega) = 0$\n",
    "        * information lost / noise added in quantization (4 vs. 6 vs. 8 bits) \n",
    "* $D_{KL}(P||Q)$ \"seeks the mean\" since:\n",
    "    * $\\sum p(\\omega) = \\sum q(\\omega) = 1$\n",
    "    * $D_{KL}$ penalty is proportional to $p(\\omega)$\n",
    "    * penalty is sensitive to small Q\n",
    "    * no (direct) penalty assigned where $p(\\omega) = 0, q(\\omega) > 0$\n",
    "        * indirectly penalized because $\\sum q(\\omega) < 1$ where $p(\\omega) > 0$\n",
    "    * $D_{KL} > 0$ is sub-optimal encoding, or \"misallocation of bit-length\" compared to optimal (observed / true distribution) due to incorrect frequency estimation\n",
    "* we want to maximize mutual information between $R$ and $Z$\n",
    "    * let $n = 2^b$ represent the dictionary size, where $b$ is the bitrate\n",
    "    * larger dictionary preserves more information for $\\delta$ to learn from\n",
    "    * 6 bit quantization yields lower model error than 4 bit, 8 bits lower than 6, etc.\n",
    "    * as dictionary size grows, overquantization starts to cause problems in $D_{KL}$ (empty bins)\n",
    "    * $p(\\omega) = 0$ over-quantization isn't a problem, but $Q = 0$ is prior distribution problem, discussed next.\n",
    "* calculate $D_{KL}$ for increasing bitrate until over-quantization causes divergence\n",
    "    * balances preserving information and suppressing quantization noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf586c-18c1-470c-9e2e-36544889be7e",
   "metadata": {},
   "source": [
    "### **Problem 2:** Choosing an Appropriate Prior Distribution\n",
    "\n",
    "Given the divergence of the observed distribution $P$ from the simulated distribution $Q$ from the KL divergence:\n",
    "\n",
    "$$D_{KL}(P_i || Q_j) = \\sum_{\\omega \\in \\mathcal{\\Omega}} P_i(\\omega) \\log \\left( \\frac{p_i(\\omega)}{q_j(\\omega)} \\right) $$\n",
    "\n",
    "#### Unobserved state(s) $p(\\omega) = 0$\n",
    "\n",
    "For $p(\\omega) = 0, q(\\omega) > 0$, we assign $D_{KL}|_{p(\\omega)=0} = 0$ by L'Hôpital's Rule:\n",
    "\n",
    "$$\\lim_{p(\\omega) \\to 0} \\log \\left(\\frac{p(\\omega_i)}{q(\\omega_i)} \\right) = \\lim_{x \\to 0^+} \\frac{\\log (x)}{x^{-1}}$$\n",
    "\n",
    "* Differentiate $f(x) = \\log(x)$ and $g(x) = x^{-1}$ with respect to x:\n",
    "    * $f'(x) = \\frac{d}{dx}\\left[log(x) \\right] = \\frac{1}{x}$  \n",
    "    * $g'(x) = \\frac{d}{dx}\\left[x^{-1} \\right] = -x^{-2}$  \n",
    "* Take the limit of the ratio of $f'(x)$ and $g'{x)}$ as $x \\to 0$:  \n",
    "    \n",
    "$$\\lim_{x \\to 0} \\frac{\\frac{1}{x}}{\\frac{-1}{x^2}} = \\lim_{x \\to 0} -x = 0$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c480254-8d94-46f7-9e62-0ad3fcd231fe",
   "metadata": {},
   "source": [
    "#### Unpredicted state(s) $q(\\omega) = 0$\n",
    "\n",
    "States where $q(\\omega) = 0$ cannot be neglected since the resulting $D_{KL}$ would suggest falsely close distributions, in some cases yielding negative divergence.\n",
    "\n",
    "* let $\\alpha$ represent a prior distribution for the model predictions $Q$\n",
    "* small $\\alpha$ corresponds to strong belief in the model, and vice versa\n",
    "* choose $\\alpha$ that is minimally influential on the posterior $Q$\n",
    "* observed records are of different lengths,\n",
    "    * express $q(\\omega)$ in terms of **event counts**\n",
    "    * assume a uniform distribution of 1 pseudo-count $\\alpha = (1)_{i=1}^{2^b}$\n",
    "    * renormalizing by total counts implicitly adjusts the \"strength of belief\" in the observations.\n",
    "        * longer records divide the prior (1) by a larger number resulting in a smaller prior, and vice-versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fbfdd-f4b4-42b2-98d7-f8eba893fc26",
   "metadata": {},
   "source": [
    "#### Varying $\\alpha$\n",
    "\n",
    "* consider the case where $0 > \\alpha < 1$:\n",
    "    * smaller $\\alpha$ results in larger $D_{KL}$ where $q(\\omega) = 0, p(\\omega) > 0$\n",
    "    * smaller $\\alpha$ indicates increasing preference for selecting a model (proxy location) that prioritizes optimal encoding on **extreme frequencies**.\n",
    "        * analogous to noise shaping in audio processing?\n",
    "    * less clear implications for information / compression interpretation\n",
    "* consider the case where $\\alpha \\gg 1$\n",
    "    * increasing $\\alpha$ corresponds to decreasing strength of belief in the model\n",
    "        * could it also reflect weaker belief in the accuracy of observations (since Q is observed data at $j$)?\n",
    "    * let $\\mathcal{U}$ represent the uniform distribution in the range $[a, b]$.\n",
    "    * $\\lim_{\\alpha \\to \\infty} D_{KL} = \\sum p(\\omega)\\log \\frac{p(\\omega)}{\\mathcal{U}}$\n",
    "    * $\\sum q(\\omega)|_{p(\\omega) = 0} < 1$, and it decreases by $1/N$ as $\\alpha \\to \\infty$ for each state $p(\\omega) = 0$\n",
    "        * $D_{KL}$ is sensitive to small $p$, where a large $\\alpha$ and small $p(\\omega)$ yield $\\frac{p(\\omega)}{q(\\omega)} < 1 \\to \\log \\frac{p(\\omega)}{q(\\omega)} < 0$\n",
    "        * as the number of unobserved states increases (overquantization), $D_{KL}$ increases since the ratios $\\frac{p(\\omega)}{q(\\omega)}$ increase with decreasing $q(\\omega)$\n",
    "* For $(R_i, R_j)$ pairs where $q(\\omega) > 0 \\text{ for all } \\omega$, assuming a uniform $\\alpha = (1)_{i=1}^{2^b}$ yields very little influence on $Q$ since the minimum number of observations is $\\approx 10^3$,\n",
    "* Where $q(\\omega) = 0, p(\\omega) > 0$, $D_{KL}$ is minimized when the prior $\\alpha = (1)_{i=1}^{2^b}$ is assumed, and it increases as $\\alpha$ changes in both directions towards zero and infinity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3f662-a655-41ee-8e11-baf7b1759e1b",
   "metadata": {},
   "source": [
    "### **Problem 3**: Model Uncertainty\n",
    "\n",
    "* combine all predicted and observed values from the MC simulation trials\n",
    "* define some number of intervals ($n_{intervals}$) of $\\hat Y$ and compute the distribution of $Y$ in each interval. \n",
    "    * set intervals (bins) by:\n",
    "        * minimum sample size\n",
    "        * minimum \"interesting\" difference in $\\hat Y$\n",
    "    * because we've used Monte Carlo simulation to generate large samples in each bin, we can make a two-sided t-test arbitrarily sensitive to differences in mean between bins, so p-values are kind of meaningless and we should incoporate an effect size.\n",
    "* The final step is to map all $G_{k} > 0$ back to spatial coordinates to serve as a decision tool, \n",
    "    * greater $G_{k}$ is associated with greater expected information for the total decision space by adding a monitoring station at location $k$.\n",
    "    * how should uncertainty in $G_k$ be expressed given:\n",
    "        * model residuals are heteroscedastic\n",
    "            * can we assume errors are independent?\n",
    "        * each $G_k$ is the sum of many predicted values from as many as $n_{intervals}$ unique error distributions\n",
    "* The aim is to provide confidence intervals for $G_k$ to use in comparing the expected information gain from monitoring one location over another\n",
    "    * let $\\epsilon$ represent the minimum expected additional information in order to consider monitoring at one location to be advantageous over another.\n",
    "        * $G_k - G_l > \\epsilon$ can then be used to reduce the complexity / computation / decision space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf3057-2202-4249-97b2-5f460dd6ec5f",
   "metadata": {},
   "source": [
    "### Network Contraction Problem\n",
    "\n",
    "Since network contraction doesn't eliminate existing information:  \n",
    "\n",
    "* how do we value continuous/current/historical records?\n",
    "* how is marginal information valued?\n",
    "* is there an optimal replacement strategy path (i.e. move n stations)?\n",
    "* i.e. incorporate factors describing:\n",
    "    * reliability (hydraulic control stability, site exposure)\n",
    "    * servicing cost (travel time, remoteness factor)\n",
    "    * worker safety factor (maybe same as remoteness)\n",
    "    * cost of aquiring existing private data in vicinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28a527-b88e-419a-a54c-06f079de4631",
   "metadata": {
    "tags": []
   },
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Random Forest Vs. Gradient-Boosted Trees\n",
    "\n",
    "### RF\n",
    "* build a large number of *complete* decision trees based on bootstrap resampling, average the predictions.\n",
    "* each tree is trained on a bootstrap (random) sample and builds trees by random feature subsets at each node (supposed to help protect against overfitting)\n",
    "\n",
    "### GBDT\n",
    "* build (ensembles of small) trees in series, weightings in subsequent trees are adjusted by errors of previous iteration.\n",
    "* uses gradient descent to add new model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f2c69-0693-4452-8838-4922621bd759",
   "metadata": {
    "tags": []
   },
   "source": [
    "Given a dataset $X$ consisting of $N$ observations, where each observation $x_i$ comprises two components: a time series $T_i$ and static descriptive indices $D_i$, we aim to find the model parameters $\\theta$ that minimize the discrepancy between observed outcomes $Y$ and predicted outcomes $\\hat{Y}$. The discrepancy is quantified by the loss function $\\mathcal{L}(Y, \\hat{Y})$.\n",
    "\n",
    "- **Data Representation**: \n",
    "  - $X = \\{(T_1, D_1), (T_2, D_2), ..., (T_N, D_N)\\}$\n",
    "\n",
    "- **Quantization Scheme**: \n",
    "  - $Z_i = Q(T_i)$, where $Q$ is a quantization scheme applied to the time series component $T_i$ to produce a discretized representation $Z_i$.\n",
    "\n",
    "- **Model**: \n",
    "  - $\\hat{Y}_i = \\delta(D_i; \\theta)$, where $\\delta$ is the model operating on the static descriptive indices $D_i$ parameterized by $\\theta$, to predict outcomes $\\hat{Y}_i$.\n",
    "\n",
    "- **Loss Function**: \n",
    "  - $\\mathcal{L}(Y, \\hat{Y})$ quantifies the discrepancy between observed outcomes $Y$ and predicted outcomes $\\hat{Y}$.\n",
    "\n",
    "The objective is to find the optimal model parameters $\\theta$ that minimize the loss function $\\mathcal{L}(Y, \\hat{Y})$.\n",
    "\n",
    "## General Form\n",
    "\n",
    "Given a large dataset $X$ of dimension $M$, define and calibrate a model $\\delta(\\theta)$ to minimize the discrepancy between observed outcomes $Y$ and predicted outcomes $\\hat Y$.  The discrepancy is quantified by a loss function $l(Y, \\hat Y)$ where $\\hat Y$ is obtained through the model $\\delta (Z;\\theta)$.  Here, $Z$ is a transformed representation of X achieved through a quantization strategy $Q$, such that $Z = Q(U)$.  The quantization strategy $Q$ is chosen to minimize quantization noise and maximize the mutual information between X and Z.\n",
    "\n",
    "## Context\n",
    "\n",
    "The first step is to find the quantization mapping $C$ to $Z$, $Z=Q(U)$, that maximizes the entropy of $Y(Z)$: $$\\max\\limits_{Q} H(Y(Q(U))$$\n",
    "\n",
    "under the condition that $Q$ is penalized by the quantization noise $R(Q)$: $$\\max\\limits_{Q} H(Y(Q(U))) - \\lambda R(Q)$$\n",
    "\n",
    "The second step is to minimize the prediction error (or loss $l$) of model $\\delta(Z;\\theta)$: $$\\min\\limits_{\\delta,\\theta} l(Y, \\delta(Z; \\theta)$$\n",
    "\n",
    "The third step is to be able to map new $X$ to $\\hat Y$ and express risk derived from Monte Carlo Simulation where $\\delta$ is minimized by $\\theta^*$ for random samples of $X^* \\in \\hat X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa14458-b89e-421f-8763-6caad834d17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Results Exploration\n",
    "\n",
    "Using Monte Carlo simulation, we have generated a large sample of $\\theta$ to evaluate via $\\delta(\\theta)$ using xgboost, in other words we have a distribution of $\\theta$ for a given $\\delta$.  \n",
    "\n",
    "The goal now is to evaluate the loss as a function of the predicted $\\hat Y$.  To do this, we set up some number of simulations where we hold $\\theta$ fixed but randomly select K stations to leave out of the training data completely (since each training sample is a pair of basins, the K stations must be left out of pairings altogether.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc2038-c943-4e3c-ac80-026faede5f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ca645-c982-45ba-9099-1e6dc3342d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.layouts import gridplot, column, row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Category20, Set2\n",
    "import numpy as np\n",
    "output_notebook()\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329117e5-04be-405e-ac3c-be9ef2c68520",
   "metadata": {},
   "source": [
    "We used gradient boosted decision trees to find a model that tries to predict divergence of runoff distributions from basin attributes.\n",
    "\n",
    "Along with $D_{KL}$ measures as a function of quantization $C$ and prior $\\alpha$ are other common measures: \n",
    "* coefficient of determination ($R^2$) \n",
    "* Nash Sutcliffe Efficiency (NSE)\n",
    "* Kling-Gupta Efficiency (KGE), and\n",
    "* Total Variation distance\n",
    "\n",
    "Before getting into XGBoost model calibration, let's look at the distribution of the above metrics across quantization schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b75d9-e68a-4045-8ba8-b57c4b5d46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(b, revision_date='20240409'):\n",
    "    result_folder = os.path.join(BASE_DIR, 'processed_data', 'dkl_test_results')\n",
    "    result_fname = f'DKL_results_{b}bits_{revision_date}.csv'\n",
    "    results_fpath = os.path.join(result_folder, result_fname)\n",
    "    df = pd.read_csv(results_fpath, dtype={'proxy': str, 'target': str})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0afef-3547-446b-925e-8d4dd7280afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitrates = [4, 5, 6, 7, 8]\n",
    "bitrates = [8]\n",
    "\n",
    "model_cols = ['cod', 'nse', 'kge', 'tvd'] \n",
    "dkl_cols = ['dkl_sim', 'dkl_post_0.001R', 'dkl_post_0.01R', 'dkl_post_0.1R',\n",
    "       'dkl_post_0R', 'dkl_post_1R', 'dkl_post_2R', 'dkl_post_5R',\n",
    "       'dkl_post_10R', 'dkl_post_20R', 'dkl_post_50R', 'dkl_post_100R',\n",
    "       'dkl_post_200R', 'dkl_post_500R', 'dkl_post_1000R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f238d-b7d8-4e53-b6d6-70a5f4f3cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data in the same dataframe\n",
    "rdf = pd.DataFrame()\n",
    "\n",
    "for b in bitrates:\n",
    "    df = load_data(b)\n",
    "    pairs = df.apply(lambda row: f\"{row['proxy']}-{row['target']}\", axis=1).values\n",
    "    df['id'] = pairs\n",
    "    df.set_index('id', inplace=True)\n",
    "    data = df[dkl_cols + model_cols].copy()\n",
    "    data.columns = [f'{b}_{c}' for c in data.columns]\n",
    "    if rdf.empty:\n",
    "        rdf = data.copy()\n",
    "    else:\n",
    "        rdf = pd.concat([rdf, data], join='inner', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647d514-532e-4c70-b5db-152fef244f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for c in model_cols:\n",
    "    fig = figure(title=c, x_axis_label=c, y_axis_label='P(X)')\n",
    "    n = 0\n",
    "    for b in bitrates:\n",
    "        vals = rdf[f'{b}_{c}'].values\n",
    "        hist, edges = np.histogram(vals, bins=50, density=True)\n",
    "        x = (edges[:-1] + edges[1:]) / 2\n",
    "        fig.line(x, hist, line_color=Set2[6][n], legend_label=f'{b}bits',\n",
    "                line_width=3)\n",
    "        n += 1\n",
    "    plots.append(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f32080-4138-41ea-9267-c89fe9ec07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gridplot(plots, ncols=2, width=600, height=350)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef7ba5-c7a3-46d1-964f-7c18f04b3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for c in dkl_cols:\n",
    "    fig = figure(title=c, x_axis_label=c, y_axis_label='P(X)')\n",
    "    n = 0\n",
    "    for b in bitrates:\n",
    "        vals = rdf[f'{b}_{c}'].values\n",
    "        hist, edges = np.histogram(vals, bins=50, density=True)\n",
    "        x = (edges[:-1] + edges[1:]) / 2\n",
    "        fig.line(x, hist, line_color=Set2[6][n], legend_label=f'{b}bits',\n",
    "                line_width=3)\n",
    "        n += 1\n",
    "    plots.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25998a-0ab1-4f8e-b855-b6bfa2330a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layout = gridplot(plots, ncols=2, width=600, height=350)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9a094-1af8-45b6-b801-26737d6c35eb",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**At the individual pair level** check how much the $D_{KL}$ measure diverges for all $\\alpha$ as we go from $4 \\to 8$ bits encoding.  What is the effect of underquantization occurring in the middle instead of at the edges?  It seems to be a vestige of the quantization and the metric $D_{KL}$, but it still represents a real inefficiency in encoding.\n",
    "\n",
    "How can the appearance of \"missing bins\" be interpreted.  The greater the detail we look at distributions,  to match as we increase the dictionary size.  The penalty is implicitly adjusted here as well since the uniform prior distributes $\\frac{\\alpha_i}{2^b}$ probability to each bin, so as the dictionary size increases, the penalty \n",
    "\n",
    "We do not apply a prior to $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41328539-54c3-4ecb-887e-65d348858053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame()\n",
    "for c in dkl_cols:\n",
    "    if c.endswith('dkl_sim'):\n",
    "        continue\n",
    "    # for b in bitrates:\n",
    "    # for bi in range(1, len(bitrates)):\n",
    "    baseline_col = f'4_{c}'\n",
    "    for b in bitrates[1:]:\n",
    "        ddf[f'{b}_{c}_diff'] = rdf[f'{b}_{c}'] - rdf[baseline_col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9a075-2081-4cd0-a1b7-178d4bad5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "print(dkl_cols)\n",
    "for c in [e for e in dkl_cols if not e.endswith('_0R')]:\n",
    "    if c == 'dkl_sim':\n",
    "        continue\n",
    "    fig = figure(title=f'quantization assessment: {c}', width=800, height=400)\n",
    "    n = 0\n",
    "    for b in bitrates[1:]:\n",
    "        vals = ddf[f'{b}_{c}_diff'].values\n",
    "        hist, edges = np.histogram(vals, bins=50, density=True)\n",
    "        x = (edges[:-1] + edges[1:]) / 2\n",
    "        fig.line(x, hist, line_color=Set2[len(bitrates)][n], legend_label=f'{b}bits',\n",
    "                line_width=3)\n",
    "        n += 1\n",
    "    plots.append(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e491e-a94d-447f-9fe8-cead1b33819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gridplot(plots, ncols=5, width=300, height=200)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbbc02-a1f9-4ee3-b1bb-2853526da17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots  = []\n",
    "for c in [e for e in dkl_cols if not e.endswith('_0R')]:\n",
    "    if c == 'dkl_sim':\n",
    "        continue\n",
    "    if c.endswith('_1R'):\n",
    "        continue\n",
    "    fig = figure(title=f'{c}', width=800, height=400, output_backend='webgl')\n",
    "    n = 0\n",
    "    baseline_vals = rdf[f'4_{c}'].copy()\n",
    "    for b in bitrates[1:][::-1]:\n",
    "        vals = rdf[f'{b}_{c}'].values\n",
    "        fig.circle(baseline_vals, vals, color=Set2[len(bitrates)][n], legend_label=f'{b}bits',\n",
    "                size=1, alpha=0.2)\n",
    "        n += 1\n",
    "    fig.legend.click_policy='hide'\n",
    "    plots.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6077c-8338-4fba-9b04-9e5a6372e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = gridplot(plots, ncols=5, width=300, height=200)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c38233-2586-4e08-85b4-c6cbe929389f",
   "metadata": {},
   "source": [
    "### Aggregate results from trials across an MC simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33190fde-c25f-420a-aea0-d21d575f119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the files for one simulation\n",
    "# sim_identifier = 'n_estimators_75'\n",
    "# max_depth_id = 'max_depth_7'\n",
    "# lr_id = 0.144\n",
    "# sim_identifier = 'n_estimators_98'\n",
    "# max_depth_id = 'max_depth_6'\n",
    "# lr_id = 0.07\n",
    "# sim_identifier = 'n_estimators_93'\n",
    "# max_depth_id = 'max_depth_6'\n",
    "# lr_id = 0.112\n",
    "# estimators = 35\n",
    "# max_depth = 7\n",
    "# lr_id = 0.234\n",
    "# estimators = 33\n",
    "# max_depth = 8\n",
    "# lr_id = 0.196\n",
    "# estimators = 97\n",
    "# max_depth = 8\n",
    "# lr_id = 0.141\n",
    "# estimators = 97\n",
    "# max_depth = 8\n",
    "# lr_id = 0.310\n",
    "estimators = 89\n",
    "max_depth = 5\n",
    "lr_id = 0.093\n",
    "\n",
    "sim_identifier = f'n_estimators_{estimators}'\n",
    "max_depth_id = f'max_depth_{max_depth}'\n",
    "\n",
    "\n",
    "sim_files = sorted([e for e in os.listdir('xval_results') if sim_identifier in e])\n",
    "sim_files = [e for e in sim_files if max_depth_id in e]\n",
    "sim_files = [e for e in sim_files if round(float(e.split('_')[16]), 3) == lr_id]\n",
    "# sim_files = sorted([e for e in os.listdir('xval_results') if int(e.split('_')[0]) == sim_id])\n",
    "print(len(sim_files))\n",
    "print(sim_files[0])\n",
    "# for i, v in enumerate(sim_files[0].split('_')):\n",
    "#     print(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821170a4-5dbc-43d1-809c-e5a0a04750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame()\n",
    "sim_df['file'] = sim_files\n",
    "sim_df[\"sim_no\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "sim_df[\"bits\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[2]))\n",
    "sim_df[\"max_depth\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[10]))\n",
    "sim_df['prior'] = sim_df['file'].apply(lambda x: float(x.split('_')[4]))\n",
    "sim_df[\"n_estimators\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[13]))\n",
    "sim_df[\"learning_rate\"] = sim_df[\"file\"].apply(lambda x: float(x.split(\"_\")[16]))\n",
    "sim_df[\"colsample_bytree\"] = sim_df[\"file\"].apply(lambda x: float(x.split(\"_\")[19]))\n",
    "# sim_df[\"lambda\"] = sim_df[\"file\"].apply(lambda x: float(x.split(\"_\")[19]))\n",
    "# sim_df[\"alpha\"] = sim_df[\"file\"].apply(lambda x: float(x.split(\"_\")[21]))\n",
    "sim_df[\"mse\"] = sim_df[\"file\"].apply(lambda x: float(x.split(\"_\")[21]))\n",
    "sim_df[\"n_train\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[22]))\n",
    "sim_df[\"n_test\"] = sim_df[\"file\"].apply(lambda x: int(x.split(\"_\")[24]))\n",
    "sim_df.sort_values('sim_no', inplace=True)\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f992f-f06c-4679-86d4-2d8c41f26acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = list(set(sim_df['bits']))[0]\n",
    "prior = list(set(sim_df['prior']))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ab162-6c33-441d-b13b-c58f63ac107e",
   "metadata": {},
   "source": [
    "First, lets get an understanding of the distribution of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedb7b2-1c03-4f35-9019-38faa0e242f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, lets get an understanding of the distribution of predicted values\n",
    "predictions = []\n",
    "actuals = []\n",
    "eqp_edges = []\n",
    "eqw_edges = []\n",
    "n_bins = 20\n",
    "all_max, all_min = -1e6, 1e6\n",
    "for i, row in sim_df.iterrows():\n",
    "    sim_id = row['sim_no']\n",
    "    file = row['file']\n",
    "    mae = row['mse']\n",
    "    sim = pd.read_csv(f'xval_results/{file}')\n",
    "\n",
    "    preds = sim['predicted'].values\n",
    "    predictions += list(preds)\n",
    "    actuals += list(sim['actual'].values)\n",
    "    if min(preds) < all_min:\n",
    "        all_min = min(preds)\n",
    "    if max(preds) > all_max:\n",
    "        all_max = max(preds)\n",
    "    # add a small amount of random noise to avoid ties\n",
    "    preds += np.random.uniform(-1e-6, 1e-6, len(preds))\n",
    "    sim_sorted = sorted(preds)\n",
    "    hist, edges = np.histogram(sim_sorted, n_bins-1, density=True)\n",
    "    eqw_edges.append(list([0] + edges.tolist()))\n",
    "    \n",
    "    # Calculate the percentiles to split the preds array\n",
    "    percentiles = np.linspace(0, 100, n_bins + 1)\n",
    "    \n",
    "    # Compute the bin edges using the percentiles\n",
    "    bin_edges = np.percentile(preds, percentiles)\n",
    "    \n",
    "    # Ensure uniqueness by handling potential duplicates in bin_edges\n",
    "    unique_bin_edges = np.unique(bin_edges)\n",
    "    # Handle the rare case where uniqueness filtering reduces the number of edges\n",
    "    if len(unique_bin_edges) < len(bin_edges):\n",
    "        raise ValueError(\"Reduced bin edges due to duplicates. Consider fewer bins or different data.\")\n",
    "    else:\n",
    "        eqp_edges.append(unique_bin_edges)\n",
    "    \n",
    "\n",
    "print('min: ', all_min, ' max: ', all_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14132efb-9ef3-4285-bb49-bc33158d6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.DataFrame({'Predicted': predictions, 'Observed': actuals})\n",
    "# Compute the 95% confidence interval\n",
    "min_pred, max_pred = adf['Predicted'].min(), adf['Observed'].max()\n",
    "eval_x = np.arange(min_pred, max_pred, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e14b73-6cca-4e0a-8ee1-f634710bc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(adf)\n",
    "afig = figure(width=600, height=400, title=f'Aggregated MC Simulation ({bits}bits, {prior}prior)', output_backend='webgl')\n",
    "afig.circle('Predicted', 'Observed', color='dodgerblue', size=1, alpha=0.5, source=source)\n",
    "# afig.line(eval_x, smoothed, line_width=3, line_color='black')\n",
    "# afig.line(eval_x, bottom, line_width=3, line_color='black', line_dash='dotted')\n",
    "# afig.line(eval_x, top, line_width=3, line_color='black', line_dash='dotted')\n",
    "afig.line([0, max(adf['Predicted'])], [0, max(adf['Predicted'])], color='red', width=3, line_dash='dashed')\n",
    "afig.xaxis.axis_label = 'Predicted D_KL'\n",
    "afig.yaxis.axis_label = 'Actual D_KL'\n",
    "# show(afig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e3184-f6ad-4f99-b237-9c88058ae3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_df = pd.DataFrame()\n",
    "ed_df['ew'] = pd.DataFrame(eqw_edges).mean(0)\n",
    "ed_df['ep'] = pd.DataFrame(eqp_edges).mean(0)\n",
    "ed_df.loc[0, :] = all_min - 1e-6\n",
    "ed_df.loc[max(ed_df.index), :] = all_max + 1e-6\n",
    "# ed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848795c7-8e72-4f1d-bf92-fb7b5eea8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_counts, ep_counts = [], []\n",
    "ep_probs, ew_probs = [], []\n",
    "for i, row in sim_df.iterrows():\n",
    "    sim_id = row['sim_no']\n",
    "    file = row['file']\n",
    "    mae = row['mse']\n",
    "    sim = pd.read_csv(f'xval_results/{file}')\n",
    "    preds = sim['predicted'].values\n",
    "    # ew_bin_counts = np.zeros(n_bins)\n",
    "    # ep_bin_counts = np.zeros(n_bins)\n",
    "    ew_edges = ed_df['ew'].to_numpy()\n",
    "    ep_edges = ed_df['ep'].to_numpy()\n",
    "    \n",
    "    ew_bins = np.digitize(preds, ew_edges) - 1\n",
    "    ep_bins = np.digitize(preds, ep_edges) - 1\n",
    "    # unique_bins, counts = np.unique(ew_bins, return_counts=True)\n",
    "    \n",
    "    ew_bin_counts = np.bincount(ew_bins, minlength=n_bins)\n",
    "    ep_bin_counts = np.bincount(ep_bins, minlength=n_bins)\n",
    "        \n",
    "    # Calculate probabilities\n",
    "    ew_prob = ew_bin_counts / ew_bin_counts.sum()\n",
    "    ep_prob = ep_bin_counts / ep_bin_counts.sum()\n",
    "    \n",
    "    ew_probs.append(ew_prob.tolist())\n",
    "    ep_probs.append(ep_prob.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657ce96-411b-46e6-a334-88b020f6dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame()\n",
    "pdf['ew'] = pd.DataFrame(ew_probs).mean(0)\n",
    "pdf['ep'] = pd.DataFrame(ep_probs).mean(0)\n",
    "# pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4853d-92ad-42ca-90e2-9751e17ea9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_widths = np.diff(ed_df['ew'])\n",
    "ep_widths = np.diff(ed_df['ep'])\n",
    "ew_cents = ed_df['ew'][:-1] + ew_widths / 2\n",
    "ep_cents = ed_df['ep'][:-1] + ep_widths / 2\n",
    "\n",
    "source_df = pd.DataFrame()\n",
    "source_df['ep_cents'] = ep_cents\n",
    "source_df['ew_cents'] = ew_cents\n",
    "source_df['ep_p'] = pdf['ep'].values\n",
    "source_df['ew_p'] = pdf['ew'].values\n",
    "source_df['ew_w'] = ew_widths\n",
    "source_df['ep_w'] = ep_widths\n",
    "print(len(source_df))\n",
    "print(len(ed_df))\n",
    "source = ColumnDataSource(source_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be45ba-fabe-4f13-b55d-86c25cb5aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bokeh plot (vertical bars)\n",
    "p = figure(width=600, height=400, title=\"Histogram of Probabilities\",\n",
    "           x_axis_label='Bins', y_axis_label='Probability')\n",
    "\n",
    "# Add vertical bars to the plot\n",
    "p.vbar(x='ew_cents', top='ew_p', width='ew_w', source=source, fill_alpha=0.6,\n",
    "       legend_label=\"Equal Width\", fill_color='navy', line_color='white')\n",
    "p.vbar(x='ep_cents', top='ep_p', width='ep_w', source=source, fill_alpha=0.6,\n",
    "       legend_label=\"Equal Probability\", fill_color='orange', line_color='white')\n",
    "\n",
    "p.legend.click_policy='hide'\n",
    "# show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b87603-8202-470c-a08a-786b12af1f34",
   "metadata": {},
   "source": [
    "For both binning methds, iterate through the simulations and collect the containing residuals.\n",
    "\n",
    "The bins will get very large, so from these we can compute in-bin distributions to evaluate the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623eed3-c013-47e2-86dc-8e3f651ff319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentiles(df, column_name, bin_size):\n",
    "    \"\"\"\n",
    "    Compute the 5th, 50th, and 95th percentiles for every bin_size chunk of ordered rows \n",
    "    in a DataFrame based on the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to process.\n",
    "    column_name (str): The name of the column to compute percentiles for.\n",
    "    bin_size (int): The number of rows in each chunk.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the percentiles for each chunk.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the percentile results\n",
    "    percentiles_list = []\n",
    "    final_bin = False\n",
    "    for start_idx in range(0, len(df), bin_size):\n",
    "        \n",
    "        end_idx = start_idx + bin_size\n",
    "        \n",
    "        if len(df) - end_idx < bin_size:\n",
    "            # Adjust the end index of the previous chunk to include the last bit\n",
    "            end_idx = len(df)\n",
    "            final_bin = True\n",
    "        chunk = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate the percentiles for the current chunk\n",
    "        percentiles = np.percentile(chunk[column_name], [5, 50, 95])\n",
    "        mean_predicted = chunk['predicted'].mean()\n",
    "        \n",
    "        # Append the results to the list\n",
    "        percentiles_list.append({\n",
    "            'start_index': start_idx,\n",
    "            'end_index': end_idx,\n",
    "            'mean_predicted': mean_predicted,\n",
    "            '5': percentiles[0],\n",
    "            '50': percentiles[1],  # Median\n",
    "            '95': percentiles[2],\n",
    "        })\n",
    "        if final_bin:\n",
    "            break\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame and return\n",
    "    return pd.DataFrame(percentiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9f668-6536-463b-a4af-9470f8c09320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "bin_vals = {}\n",
    "label_dict = {}\n",
    "pred_vals, obs_vals = [], []\n",
    "for method in ['ep', 'ew']:\n",
    "    method_results = []\n",
    "    bin_vals[method] = {}\n",
    "    label_dict[method] = {}\n",
    "    for i, row in sim_df.iterrows():\n",
    "        sim_id = row['sim_no']\n",
    "        file = row['file']\n",
    "        mae = row['mse']\n",
    "        sim = pd.read_csv(f'xval_results/{file}')\n",
    "        sim.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        # preds = sim['predicted'].values\n",
    "        # sort the dataframe by the predicted value\n",
    "        sim.sort_values('predicted', inplace=True)\n",
    "        sim.reset_index(inplace=True, drop=True)\n",
    "        pred_vals += list(sim['predicted'].values)\n",
    "        obs_vals += list(sim['actual'].values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741c57a-0cb3-4470-812a-c2a14d801535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the aggregated data by predicted value and compute the confidence interval for every 1000 pts\n",
    "adf = pd.DataFrame({'predicted': pred_vals, 'actual': obs_vals})\n",
    "adf.sort_values('predicted', inplace=True)\n",
    "ci_df = compute_percentiles(adf, 'actual', 10000)\n",
    "# ci_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0b7e4-a882-45fc-84b5-14f57c81ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ew_widths = np.diff(ed_df['ew'])\n",
    "ew_cents = ed_df['ew'][:-1] + ew_widths / 2\n",
    "hs_df = pd.DataFrame()\n",
    "hs_df['ew_cents'] = ew_cents\n",
    "hs_df['ew_p'] = pdf['ew'].values\n",
    "hs_df['ew_w'] = ew_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c5883-5686-479b-a20d-044abad918fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(adf)\n",
    "afig = figure(width=600, height=400, title=f'Aggregated MC Simulations ({estimators} estimators {max_depth} max depth)', output_backend='webgl')\n",
    "afig.circle('predicted', 'actual', color='dodgerblue', size=0.5, alpha=0.25, source= source)\n",
    "afig.line(ci_df['mean_predicted'], ci_df['50'], line_width=3, line_color='black')\n",
    "afig.line(ci_df['mean_predicted'], ci_df['5'], line_width=3, line_color='black', line_dash='dotted')\n",
    "afig.line(ci_df['mean_predicted'], ci_df['95'], line_width=3, line_color='black', line_dash='dotted')\n",
    "afig.line([0, max(adf['predicted'])], [0, max(adf['predicted'])], color='red', width=3, line_dash='dashed')\n",
    "# afig.xaxis.axis_label = r'Predicted $$D_{KL}$$'\n",
    "# afig.yaxis.axis_label = r'Actual $$D_{KL}$$'\n",
    "afig.xaxis.axis_label = 'Predicted DKL'\n",
    "afig.yaxis.axis_label = 'Actual DKL'\n",
    "\n",
    "\n",
    "\n",
    "source = ColumnDataSource(hs_df)\n",
    "h = figure(width=600, height=200, title=\"Distribution of Predicted Values\",\n",
    "           x_axis_label=r'$$\\hat Y$$', y_axis_label='Probability')\n",
    "h.x_range = afig.x_range\n",
    "\n",
    "# Add vertical bars to the plot\n",
    "h.vbar(x='ew_cents', top='ew_p', width='ew_w', source=source, fill_alpha=0.6,\n",
    "       legend_label=\"Equal Width\", fill_color='navy', line_color='white')\n",
    "\n",
    "h.legend.click_policy='hide'\n",
    "\n",
    "layout = column(afig, h)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b57067-a4f8-4ca0-9da5-3a5e3d990529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bins_with_indices(main_df, bin_df, observed_col, predicted_col, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs pairwise comparisons between bins of values using the Mann-Whitney U test,\n",
    "    based on the main dataframe of observed and predicted values, and a dataframe of bin start indices.\n",
    "    \n",
    "    Parameters:\n",
    "    main_df (pandas.DataFrame): DataFrame containing observed and predicted values.\n",
    "    bin_df (pandas.DataFrame): DataFrame containing the bin start indices.\n",
    "    observed_col (str): Column name for observed values in main_df.\n",
    "    predicted_col (str): Column name for predicted values in main_df.\n",
    "    alpha (float): Significance level for determining statistical difference.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A matrix (DataFrame) of p-values from the Mann-Whitney U tests.\n",
    "    \"\"\"\n",
    "    df = main_df.copy()\n",
    "    bdf = bin_df.copy()\n",
    "    # Add end index to bin_df for easier slicing\n",
    "    bdf['end_index'] = bdf['end_index'].astype(int)\n",
    "    bdf['start_index'] = bdf['start_index'].astype(int)\n",
    "    \n",
    "    # Sorting main_df by predicted values if not already sorted\n",
    "    df.sort_values(by=predicted_col, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "        \n",
    "    num_bins = len(bdf)\n",
    "    p_values_matrix = pd.DataFrame(np.nan, index=range(num_bins), columns=range(num_bins))\n",
    "    \n",
    "    for i in range(num_bins):\n",
    "        if i % 10 == 0:\n",
    "            print(f'Processing {i}/{num_bins}')\n",
    "        start_i, end_i = bdf.loc[i, ['start_index', 'end_index']].values\n",
    "        start_i, end_i = int(start_i), int(end_i)\n",
    "        bin_i = df.loc[start_i: end_i, observed_col].copy()\n",
    "\n",
    "        p_value = np.nan\n",
    "        if bin_i.empty:\n",
    "            print(f'bin {i} has 0 len')\n",
    "            continue\n",
    "        \n",
    "        for j in range(i + 1, num_bins):\n",
    "            start_j, end_j = bdf.loc[j, ['start_index', 'end_index']].values\n",
    "            start_j, end_j = int(start_j), int(end_j)\n",
    "            bin_j = df.iloc[start_j:end_j][observed_col].copy()\n",
    "            \n",
    "            if bin_j.empty:\n",
    "                print(f'bin {j} has 0 len')\n",
    "                continue\n",
    "            \n",
    "            stat, p_value = st.mannwhitneyu(bin_i, bin_j, alternative='two-sided')\n",
    "            p_values_matrix.at[i, j] = p_value\n",
    "            p_values_matrix.at[j, i] = p_value  # The matrix is symmetric\n",
    "    \n",
    "    # Adjusting p-values for multiple comparisons if necessary\n",
    "    # Example: Bonferroni correction\n",
    "    # Adjusted alpha = alpha / number of comparisons\n",
    "    # num_comparisons = num_bins * (num_bins - 1) / 2\n",
    "    # adjusted_alpha = alpha / num_comparisons\n",
    "    \n",
    "    # Identifying significantly different pairs\n",
    "    significantly_different_pairs = (p_values_matrix < alpha).stack()\n",
    "    print(f\"Significantly different pairs of bins (at alpha level of {alpha:.3f}):\")\n",
    "    print(significantly_different_pairs[significantly_different_pairs].index.tolist())\n",
    "    \n",
    "    return p_values_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ef867-3067-4457-a86f-f2ee322a19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_bins_with_indices(adf, ci_df, 'actual', 'predicted', alpha=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f771d-c0a8-46ef-bd49-e10008cab169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
